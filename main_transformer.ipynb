{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /content/drive/MyDrive/dacon/lowresol/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip -qn open.zip -d ./open/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet timm pytorch_lightning==1.7.7 torchmetrics==0.11.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Seo\\anaconda3\\envs\\Bird\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import pytorch_lightning as L\n",
    "\n",
    "from torchinfo import summary\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import v2 as  transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import Swinv2Config, Swinv2Model, AutoImageProcessor, AutoModelForImageClassification\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "from pytorch_lightning.loggers import WandbLogger  # wandb logger를 임포트\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    NUM_DEVICES = torch.cuda.device_count()\n",
    "    NUM_WORKERS = os.cpu_count()\n",
    "    #NUM_CLASSES = 4\n",
    "    NUM_CLASSES = 25\n",
    "    EPOCHS = 16\n",
    "    BATCH_SIZE = (\n",
    "        32 if torch.cuda.device_count() < 2 \n",
    "        else (32 * torch.cuda.device_count())\n",
    "    )\n",
    "    LR = 0.001\n",
    "    APPLY_SHUFFLE = True\n",
    "    SEED = 768\n",
    "    #HEIGHT = 224\n",
    "    #WIDTH = 224\n",
    "    HEIGHT = 224\n",
    "    WIDTH = 224\n",
    "    CHANNELS = 3\n",
    "    #IMAGE_SIZE = (224, 224, 3)\n",
    "    IMAGE_SIZE = (224, 224, 3)\n",
    "    \n",
    "    # Define paths\n",
    "    #DATASET_PATH = \"/content/drive/MyDrive/Colab Notebooks/dataset\"\n",
    "    #TRAIN_PATH = '/content/drive/MyDrive/Colab Notebooks/dataset/train/'\n",
    "    #TEST_PATH = '/content/drive/MyDrive/Colab Notebooks/dataset/test'\n",
    "    \n",
    "# Mute warnings\n",
    "warnings.filterwarnings(\"ignore\", \"is_categorical_dtype\")\n",
    "warnings.filterwarnings(\"ignore\", \"use_inf_as_na\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, path_col,  mode='train'):\n",
    "        self.df = df\n",
    "        self.path_col = path_col\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == 'train':\n",
    "            row = self.df.iloc[idx]\n",
    "            image = read_image(row[self.path_col])/256.\n",
    "            label = row['class']\n",
    "            data = {\n",
    "                'image':image,\n",
    "                'label':label\n",
    "            }\n",
    "            return data\n",
    "        elif self.mode == 'val':\n",
    "            row = self.df.iloc[idx]\n",
    "            image = read_image(row[self.path_col])/256.\n",
    "            label = row['class']\n",
    "            data = {\n",
    "                'image':image,\n",
    "                'label':label\n",
    "            }\n",
    "            return data\n",
    "        elif self.mode == 'inference':\n",
    "            row = self.df.iloc[idx]\n",
    "            image = read_image(row[self.path_col])/256.\n",
    "            data = {\n",
    "                'image':image,\n",
    "            }\n",
    "            return data\n",
    "\n",
    "    def train_transform(self, image):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCollateFn:\n",
    "    def __init__(self, transform, mode):\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        if self.mode=='train':\n",
    "            pixel_values = torch.stack([self.transform(data['image']) for data in batch])\n",
    "            label = torch.LongTensor([data['label'] for data in batch])\n",
    "            return {\n",
    "                'pixel_values':pixel_values,\n",
    "                'label':label,\n",
    "            }\n",
    "        elif self.mode=='val':\n",
    "            pixel_values = torch.stack([self.transform(data['image']) for data in batch])\n",
    "            label = torch.LongTensor([data['label'] for data in batch])\n",
    "            return {\n",
    "                'pixel_values':pixel_values,\n",
    "                'label':label,\n",
    "            }\n",
    "        elif self.mode=='inference':\n",
    "            pixel_values = torch.stack([self.transform(data['image']) for data in batch])\n",
    "            return {\n",
    "                'pixel_values':pixel_values,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.clf = nn.Sequential(\n",
    "            nn.Tanh(),\n",
    "            nn.LazyLinear(25),\n",
    "        )\n",
    "\n",
    "#     @torch.compile\n",
    "    def forward(self, x, label=None):\n",
    "        # original\n",
    "        # x = self.model(x).pooler_output\n",
    "        x = self.model(x)\n",
    "        # pooler_output 대신에 last_hidden_state 사용\n",
    "        #x = outputs.last_hidden_state[:, 0]  # [CLS] 토큰에 해당하는 벡터 추출\n",
    "        #x = self.clf(x)\n",
    "        loss = None\n",
    "        if label is not None:\n",
    "            loss = nn.CrossEntropyLoss()(x, label)\n",
    "        probs = nn.LogSoftmax(dim=-1)(x)\n",
    "        return probs, loss\n",
    "\n",
    "class LitCustomModel(L.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = CustomModel(model)\n",
    "        self.validation_step_output = []\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        opt = torch.optim.AdamW(self.parameters(), lr=1e-5)\n",
    "        return opt\n",
    "\n",
    "    def training_step(self, batch, batch_idx=None):\n",
    "        x = batch['pixel_values']\n",
    "        label = batch['label']\n",
    "        probs, loss = self.model(x, label)\n",
    "        self.log(f\"train_loss\", loss, on_step=True, on_epoch=False)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx=None):\n",
    "        x = batch['pixel_values']\n",
    "        label = batch['label']\n",
    "        probs, loss = self.model(x, label)\n",
    "        self.validation_step_output.append([probs,label])\n",
    "        return loss\n",
    "\n",
    "    def predict_step(self, batch, batch_idx=None):\n",
    "        x = batch['pixel_values']\n",
    "        probs, _ = self.model(x)\n",
    "        return probs\n",
    "\n",
    "    def validation_epoch_end(self, step_output):\n",
    "        pred = torch.cat([x for x, _ in self.validation_step_output]).cpu().detach().numpy().argmax(1)\n",
    "        label = torch.cat([label for _, label in self.validation_step_output]).cpu().detach().numpy()\n",
    "        score = f1_score(label,pred, average='macro')\n",
    "        self.log(\"val_score\", score)\n",
    "        self.validation_step_output.clear()\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "N_SPLIT = 5\n",
    "BATCH_SIZE = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./open/train.csv')\n",
    "train_df['img_path'] = train_df['img_path'].apply(lambda x: os.path.join('./open', x))\n",
    "train_df['upscale_img_path'] = train_df['upscale_img_path'].apply(lambda x: os.path.join('./open', x))\n",
    "le = LabelEncoder()\n",
    "train_df['class'] = le.fit_transform(train_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not len(train_df) == len(os.listdir('./open/train')):\n",
    "    raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=N_SPLIT, random_state=SEED, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_transform = transforms.Compose([\n",
    "#    transforms.Resize(size=(256,256), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "#    transforms.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
    "#])\n",
    "#val_transform = transforms.Compose([\n",
    "#    transforms.Resize(size=(256,256), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "#    transforms.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
    "#])\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(224,224), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
    "])\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(224,224), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
    "])\n",
    "\n",
    "train_collate_fn = CustomCollateFn(train_transform, 'train')\n",
    "val_collate_fn = CustomCollateFn(val_transform, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisionTransformerModel(nn.Module):\n",
    "    def __init__(self, backbone_model, name='vision-transformer', \n",
    "                 num_classes=CFG.NUM_CLASSES, device=CFG.DEVICE):\n",
    "        super(VisionTransformerModel, self).__init__()\n",
    "        \n",
    "        self.backbone_model = backbone_model\n",
    "        self.device = device\n",
    "        self.num_classes = num_classes\n",
    "        self.name = name\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(p=0.2, inplace=True), \n",
    "            nn.Linear(in_features=1000, out_features=256, bias=True),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(p=0.2, inplace=True),\n",
    "            nn.Linear(in_features=256, out_features=num_classes, bias=False)\n",
    "        ).to(device)\n",
    "        \n",
    "    def forward(self, image):\n",
    "        vit_output = self.backbone_model(image)\n",
    "        return self.classifier(vit_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vit_b32_model(\n",
    "    device: torch.device=CFG.NUM_CLASSES) -> nn.Module:\n",
    "    # Set the manual seeds\n",
    "    torch.manual_seed(CFG.SEED)\n",
    "    torch.cuda.manual_seed(CFG.SEED)\n",
    "\n",
    "    # Get model weights\n",
    "    model_weights = (\n",
    "        torchvision\n",
    "        .models\n",
    "        .ViT_L_32_Weights\n",
    "        .DEFAULT\n",
    "    )\n",
    "    \n",
    "    # Get model and push to device\n",
    "    model = (\n",
    "        torchvision.models.vit_l_32(\n",
    "            weights=model_weights\n",
    "        )\n",
    "    ).to(device) \n",
    "    \n",
    "    # Freeze Model Parameters\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ViT model\n",
    "vit_backbone = get_vit_b32_model(CFG.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_params = {\n",
    "    'backbone_model'    : vit_backbone,\n",
    "    'name'              : 'ViT-L-B32',\n",
    "    'device'            : CFG.DEVICE\n",
    "}\n",
    "\n",
    "# Generate Model\n",
    "vit_model = VisionTransformerModel(**vit_params)\n",
    "\n",
    "# If using GPU T4 x2 setup, use this:\n",
    "if CFG.NUM_DEVICES > 1:\n",
    "    vit_model = nn.DataParallel(vit_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================================================================================================\n",
       "Layer (type (var_name))                                           Input Shape          Output Shape         Param #              Trainable\n",
       "=================================================================================================================================================\n",
       "VisionTransformerModel (VisionTransformerModel)                   [32, 3, 224, 224]    [32, 25]             --                   Partial\n",
       "├─VisionTransformer (backbone_model)                              [32, 3, 224, 224]    [32, 1000]           1,024                False\n",
       "│    └─Conv2d (conv_proj)                                         [32, 3, 224, 224]    [32, 1024, 7, 7]     (3,146,752)          False\n",
       "│    └─Encoder (encoder)                                          [32, 50, 1024]       [32, 50, 1024]       51,200               False\n",
       "│    │    └─Dropout (dropout)                                     [32, 50, 1024]       [32, 50, 1024]       --                   --\n",
       "│    │    └─Sequential (layers)                                   [32, 50, 1024]       [32, 50, 1024]       (302,309,376)        False\n",
       "│    │    └─LayerNorm (ln)                                        [32, 50, 1024]       [32, 50, 1024]       (2,048)              False\n",
       "│    └─Sequential (heads)                                         [32, 1024]           [32, 1000]           --                   False\n",
       "│    │    └─Linear (head)                                         [32, 1024]           [32, 1000]           (1,025,000)          False\n",
       "├─Sequential (classifier)                                         [32, 1000]           [32, 25]             --                   True\n",
       "│    └─Flatten (0)                                                [32, 1000]           [32, 1000]           --                   --\n",
       "│    └─Dropout (1)                                                [32, 1000]           [32, 1000]           --                   --\n",
       "│    └─Linear (2)                                                 [32, 1000]           [32, 256]            256,256              True\n",
       "│    └─GELU (3)                                                   [32, 256]            [32, 256]            --                   --\n",
       "│    └─Dropout (4)                                                [32, 256]            [32, 256]            --                   --\n",
       "│    └─Linear (5)                                                 [32, 256]            [32, 25]             6,400                True\n",
       "=================================================================================================================================================\n",
       "Total params: 306,798,056\n",
       "Trainable params: 262,656\n",
       "Non-trainable params: 306,535,400\n",
       "Total mult-adds (G): 11.42\n",
       "=================================================================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 2228.29\n",
       "Params size (MB): 823.94\n",
       "Estimated Total Size (MB): 3071.49\n",
       "================================================================================================================================================="
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View model summary\n",
    "summary(\n",
    "    model=vit_model, \n",
    "    input_size=(CFG.BATCH_SIZE, CFG.CHANNELS, CFG.WIDTH, CFG.HEIGHT),\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "    col_width=20,\n",
    "    row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Seo\\anaconda3\\envs\\Bird\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtjwjddn15584\u001b[0m (\u001b[33mtjwjddn980117\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20240426_094117-gq1ujwns</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tjwjddn980117/Bird_Competition/runs/gq1ujwns' target=\"_blank\">EfficientNetV2Model_Fold0</a></strong> to <a href='https://wandb.ai/tjwjddn980117/Bird_Competition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tjwjddn980117/Bird_Competition' target=\"_blank\">https://wandb.ai/tjwjddn980117/Bird_Competition</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tjwjddn980117/Bird_Competition/runs/gq1ujwns' target=\"_blank\">https://wandb.ai/tjwjddn980117/Bird_Competition/runs/gq1ujwns</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\Seo\\anaconda3\\envs\\Bird\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:616: UserWarning: Checkpoint directory ./checkpoints/ exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\Seo\\anaconda3\\envs\\Bird\\lib\\site-packages\\pytorch_lightning\\utilities\\model_summary\\model_summary.py:410: UserWarning: A layer with UninitializedParameter was found. Thus, the total number of parameters detected may be inaccurate.\n",
      "  warning_cache.warn(\n",
      "\n",
      "  | Name  | Type        | Params\n",
      "--------------------------------------\n",
      "0 | model | CustomModel | 306 M \n",
      "--------------------------------------\n",
      "262 K     Trainable params\n",
      "306 M     Non-trainable params\n",
      "306 M     Total params\n",
      "1,227.192 Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Seo\\anaconda3\\envs\\Bird\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Seo\\anaconda3\\envs\\Bird\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|█████     | 660/1320 [01:38<01:38,  6.72it/s, loss=3.03, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 528: 'val_score' reached 0.26265 (best 0.26265), saving model to './checkpoints/Transformer=0-epoch=00-train_loss=3.1153-val_score=0.2627.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1320/1320 [03:13<00:00,  6.80it/s, loss=2.79, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 1056: 'val_score' reached 0.48045 (best 0.48045), saving model to './checkpoints/Transformer=0-epoch=00-train_loss=2.9215-val_score=0.4805.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  50%|█████     | 660/1320 [01:06<01:06,  9.98it/s, loss=2.5, v_num=jwns]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 1584: 'val_score' reached 0.57235 (best 0.57235), saving model to './checkpoints/Transformer=0-epoch=01-train_loss=2.5842-val_score=0.5724.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1320/1320 [02:18<00:00,  9.50it/s, loss=2.24, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 2112: 'val_score' reached 0.61519 (best 0.61519), saving model to './checkpoints/Transformer=0-epoch=01-train_loss=2.4402-val_score=0.6152.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  50%|█████     | 660/1320 [01:05<01:05, 10.11it/s, loss=2, v_num=jwns]    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 2640: 'val_score' reached 0.64790 (best 0.64790), saving model to './checkpoints/Transformer=0-epoch=02-train_loss=2.0942-val_score=0.6479.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1320/1320 [02:20<00:00,  9.39it/s, loss=1.78, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 3168: 'val_score' reached 0.66560 (best 0.66560), saving model to './checkpoints/Transformer=0-epoch=02-train_loss=1.8639-val_score=0.6656.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  50%|█████     | 660/1320 [01:06<01:06,  9.95it/s, loss=1.67, v_num=jwns] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 3696: 'val_score' reached 0.69242 (best 0.69242), saving model to './checkpoints/Transformer=0-epoch=03-train_loss=1.6439-val_score=0.6924.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1320/1320 [02:20<00:00,  9.42it/s, loss=1.51, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 4224: 'val_score' reached 0.70323 (best 0.70323), saving model to './checkpoints/Transformer=0-epoch=03-train_loss=1.5581-val_score=0.7032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  50%|█████     | 660/1320 [01:06<01:06,  9.88it/s, loss=1.45, v_num=jwns] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 4752: 'val_score' reached 0.72425 (best 0.72425), saving model to './checkpoints/Transformer=0-epoch=04-train_loss=1.6350-val_score=0.7243.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1320/1320 [02:20<00:00,  9.37it/s, loss=1.39, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 5280: 'val_score' reached 0.73408 (best 0.73408), saving model to './checkpoints/Transformer=0-epoch=04-train_loss=1.2467-val_score=0.7341.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  50%|█████     | 660/1320 [01:06<01:06,  9.89it/s, loss=1.27, v_num=jwns] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 5808: 'val_score' reached 0.74676 (best 0.74676), saving model to './checkpoints/Transformer=0-epoch=05-train_loss=1.2535-val_score=0.7468.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1320/1320 [02:20<00:00,  9.39it/s, loss=1.24, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 6336: 'val_score' reached 0.75580 (best 0.75580), saving model to './checkpoints/Transformer=0-epoch=05-train_loss=1.4246-val_score=0.7558.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  50%|█████     | 660/1320 [00:58<00:58, 11.21it/s, loss=1.17, v_num=jwns] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 6864: 'val_score' reached 0.76518 (best 0.76518), saving model to './checkpoints/Transformer=0-epoch=06-train_loss=1.4462-val_score=0.7652.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1320/1320 [02:11<00:00, 10.01it/s, loss=1.08, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 7392: 'val_score' reached 0.76960 (best 0.76960), saving model to './checkpoints/Transformer=0-epoch=06-train_loss=1.0843-val_score=0.7696.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  50%|█████     | 660/1320 [01:06<01:06,  9.92it/s, loss=1.04, v_num=jwns] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 7920: 'val_score' reached 0.78052 (best 0.78052), saving model to './checkpoints/Transformer=0-epoch=07-train_loss=1.3421-val_score=0.7805.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1320/1320 [02:19<00:00,  9.45it/s, loss=1.03, v_num=jwns] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 8448: 'val_score' reached 0.78645 (best 0.78645), saving model to './checkpoints/Transformer=0-epoch=07-train_loss=1.3039-val_score=0.7864.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  50%|█████     | 660/1320 [01:07<01:07,  9.85it/s, loss=0.98, v_num=jwns] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 8976: 'val_score' reached 0.78909 (best 0.78909), saving model to './checkpoints/Transformer=0-epoch=08-train_loss=1.0182-val_score=0.7891.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1320/1320 [02:20<00:00,  9.39it/s, loss=1, v_num=jwns]    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 9504: 'val_score' reached 0.79277 (best 0.79277), saving model to './checkpoints/Transformer=0-epoch=08-train_loss=1.3331-val_score=0.7928.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  50%|█████     | 660/1320 [01:09<01:09,  9.49it/s, loss=0.888, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 10032: 'val_score' reached 0.79892 (best 0.79892), saving model to './checkpoints/Transformer=0-epoch=09-train_loss=0.9305-val_score=0.7989.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1320/1320 [02:17<00:00,  9.63it/s, loss=0.933, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 10560: 'val_score' reached 0.80089 (best 0.80089), saving model to './checkpoints/Transformer=0-epoch=09-train_loss=1.1694-val_score=0.8009.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:  50%|█████     | 660/1320 [01:00<01:00, 10.85it/s, loss=0.889, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 11088: 'val_score' reached 0.80320 (best 0.80320), saving model to './checkpoints/Transformer=0-epoch=10-train_loss=0.9527-val_score=0.8032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 1320/1320 [02:09<00:00, 10.22it/s, loss=0.861, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 11616: 'val_score' reached 0.80878 (best 0.80878), saving model to './checkpoints/Transformer=0-epoch=10-train_loss=1.1398-val_score=0.8088.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:  50%|█████     | 660/1320 [01:06<01:06,  9.93it/s, loss=0.846, v_num=jwns] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 12144: 'val_score' reached 0.81069 (best 0.81069), saving model to './checkpoints/Transformer=0-epoch=11-train_loss=0.9367-val_score=0.8107.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 1320/1320 [02:15<00:00,  9.73it/s, loss=0.879, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 12672: 'val_score' reached 0.81576 (best 0.81576), saving model to './checkpoints/Transformer=0-epoch=11-train_loss=1.0849-val_score=0.8158.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12:  50%|█████     | 660/1320 [01:02<01:02, 10.48it/s, loss=0.789, v_num=jwns] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 13200: 'val_score' reached 0.81709 (best 0.81709), saving model to './checkpoints/Transformer=0-epoch=12-train_loss=0.9641-val_score=0.8171.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 1320/1320 [02:13<00:00,  9.90it/s, loss=0.829, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 13728: 'val_score' reached 0.82133 (best 0.82133), saving model to './checkpoints/Transformer=0-epoch=12-train_loss=0.8986-val_score=0.8213.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:  50%|█████     | 660/1320 [01:01<01:01, 10.76it/s, loss=0.77, v_num=jwns]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 14256: 'val_score' reached 0.82283 (best 0.82283), saving model to './checkpoints/Transformer=0-epoch=13-train_loss=0.8635-val_score=0.8228.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 1320/1320 [02:13<00:00,  9.91it/s, loss=0.799, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 14784: 'val_score' reached 0.82648 (best 0.82648), saving model to './checkpoints/Transformer=0-epoch=13-train_loss=1.1389-val_score=0.8265.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:  50%|█████     | 660/1320 [01:00<01:00, 10.93it/s, loss=0.709, v_num=jwns] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 15312: 'val_score' reached 0.82904 (best 0.82904), saving model to './checkpoints/Transformer=0-epoch=14-train_loss=1.1153-val_score=0.8290.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 1320/1320 [02:12<00:00,  9.96it/s, loss=0.775, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 15840: 'val_score' reached 0.83266 (best 0.83266), saving model to './checkpoints/Transformer=0-epoch=14-train_loss=1.0793-val_score=0.8327.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15:  50%|█████     | 660/1320 [01:05<01:05, 10.13it/s, loss=0.704, v_num=jwns] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 16368: 'val_score' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 1320/1320 [02:06<00:00, 10.44it/s, loss=0.77, v_num=jwns] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 16896: 'val_score' reached 0.83392 (best 0.83392), saving model to './checkpoints/Transformer=0-epoch=15-train_loss=1.1470-val_score=0.8339.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16:  50%|█████     | 660/1320 [01:01<01:01, 10.70it/s, loss=0.697, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 17424: 'val_score' reached 0.83626 (best 0.83626), saving model to './checkpoints/Transformer=0-epoch=16-train_loss=0.7678-val_score=0.8363.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 1320/1320 [02:08<00:00, 10.27it/s, loss=0.708, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 17952: 'val_score' reached 0.83706 (best 0.83706), saving model to './checkpoints/Transformer=0-epoch=16-train_loss=0.8483-val_score=0.8371.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17:  50%|█████     | 660/1320 [01:01<01:01, 10.80it/s, loss=0.644, v_num=jwns] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 18480: 'val_score' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 1320/1320 [02:00<00:00, 10.92it/s, loss=0.68, v_num=jwns] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 19008: 'val_score' reached 0.83974 (best 0.83974), saving model to './checkpoints/Transformer=0-epoch=17-train_loss=0.8557-val_score=0.8397.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18:  50%|█████     | 660/1320 [01:00<01:00, 10.97it/s, loss=0.623, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, global step 19536: 'val_score' reached 0.84052 (best 0.84052), saving model to './checkpoints/Transformer=0-epoch=18-train_loss=0.6777-val_score=0.8405.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 1320/1320 [02:15<00:00,  9.73it/s, loss=0.666, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, global step 20064: 'val_score' reached 0.84162 (best 0.84162), saving model to './checkpoints/Transformer=0-epoch=18-train_loss=0.9737-val_score=0.8416.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  50%|█████     | 660/1320 [01:05<01:05, 10.05it/s, loss=0.636, v_num=jwns] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 20592: 'val_score' reached 0.84434 (best 0.84434), saving model to './checkpoints/Transformer=0-epoch=19-train_loss=0.8988-val_score=0.8443.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 1320/1320 [02:19<00:00,  9.47it/s, loss=0.668, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 21120: 'val_score' reached 0.84488 (best 0.84488), saving model to './checkpoints/Transformer=0-epoch=19-train_loss=0.9820-val_score=0.8449.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:  50%|█████     | 660/1320 [01:08<01:08,  9.58it/s, loss=0.606, v_num=jwns] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20, global step 21648: 'val_score' reached 0.84759 (best 0.84759), saving model to './checkpoints/Transformer=0-epoch=20-train_loss=0.6361-val_score=0.8476.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 1320/1320 [02:23<00:00,  9.19it/s, loss=0.644, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20, global step 22176: 'val_score' reached 0.84897 (best 0.84897), saving model to './checkpoints/Transformer=0-epoch=20-train_loss=0.7566-val_score=0.8490.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21:  50%|█████     | 660/1320 [01:06<01:06,  9.87it/s, loss=0.618, v_num=jwns] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21, global step 22704: 'val_score' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 1320/1320 [02:12<00:00,  9.94it/s, loss=0.64, v_num=jwns] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21, global step 23232: 'val_score' reached 0.84934 (best 0.84934), saving model to './checkpoints/Transformer=0-epoch=21-train_loss=0.7933-val_score=0.8493.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  50%|█████     | 660/1320 [01:06<01:06,  9.92it/s, loss=0.602, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22, global step 23760: 'val_score' reached 0.84981 (best 0.84981), saving model to './checkpoints/Transformer=0-epoch=22-train_loss=0.7207-val_score=0.8498.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 1320/1320 [02:20<00:00,  9.42it/s, loss=0.581, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22, global step 24288: 'val_score' reached 0.85332 (best 0.85332), saving model to './checkpoints/Transformer=0-epoch=22-train_loss=0.9194-val_score=0.8533.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23:  50%|█████     | 660/1320 [01:06<01:06,  9.94it/s, loss=0.579, v_num=jwns] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23, global step 24816: 'val_score' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 1320/1320 [02:12<00:00,  9.97it/s, loss=0.633, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23, global step 25344: 'val_score' reached 0.85558 (best 0.85558), saving model to './checkpoints/Transformer=0-epoch=23-train_loss=0.6737-val_score=0.8556.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24:  50%|█████     | 660/1320 [01:06<01:06,  9.90it/s, loss=0.523, v_num=jwns] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24, global step 25872: 'val_score' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1320/1320 [02:12<00:00,  9.95it/s, loss=0.591, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24, global step 26400: 'val_score' reached 0.85811 (best 0.85811), saving model to './checkpoints/Transformer=0-epoch=24-train_loss=0.8673-val_score=0.8581.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25:  50%|█████     | 660/1320 [01:06<01:06,  9.90it/s, loss=0.559, v_num=jwns] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25, global step 26928: 'val_score' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 1320/1320 [02:12<00:00,  9.95it/s, loss=0.58, v_num=jwns] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25, global step 27456: 'val_score' reached 0.85965 (best 0.85965), saving model to './checkpoints/Transformer=0-epoch=25-train_loss=1.1102-val_score=0.8597.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26:  50%|█████     | 660/1320 [01:06<01:06,  9.87it/s, loss=0.535, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26, global step 27984: 'val_score' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 1320/1320 [02:13<00:00,  9.92it/s, loss=0.633, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26, global step 28512: 'val_score' reached 0.86025 (best 0.86025), saving model to './checkpoints/Transformer=0-epoch=26-train_loss=0.8569-val_score=0.8602.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27:  50%|█████     | 660/1320 [01:06<01:06,  9.89it/s, loss=0.549, v_num=jwns] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27, global step 29040: 'val_score' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 1320/1320 [02:13<00:00,  9.91it/s, loss=0.531, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27, global step 29568: 'val_score' reached 0.86194 (best 0.86194), saving model to './checkpoints/Transformer=0-epoch=27-train_loss=0.6313-val_score=0.8619.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28:  50%|█████     | 660/1320 [01:06<01:06,  9.94it/s, loss=0.529, v_num=jwns] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28, global step 30096: 'val_score' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 1320/1320 [02:12<00:00,  9.96it/s, loss=0.571, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28, global step 30624: 'val_score' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29:  50%|█████     | 660/1320 [01:06<01:06, 10.00it/s, loss=0.491, v_num=jwns] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, global step 31152: 'val_score' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29:  50%|█████     | 660/1320 [01:06<01:06, 10.00it/s, loss=0.491, v_num=jwns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Seo\\anaconda3\\envs\\Bird\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "c:\\Users\\Seo\\anaconda3\\envs\\Bird\\lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:352: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\Seo\\anaconda3\\envs\\Bird\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:616: UserWarning: Checkpoint directory ./checkpoints/ exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type        | Params\n",
      "--------------------------------------\n",
      "0 | model | CustomModel | 306 M \n",
      "--------------------------------------\n",
      "262 K     Trainable params\n",
      "306 M     Non-trainable params\n",
      "306 M     Total params\n",
      "1,227.192 Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 23.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Seo\\anaconda3\\envs\\Bird\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Seo\\anaconda3\\envs\\Bird\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|█████     | 660/1320 [01:06<01:06,  9.99it/s, loss=0.531, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 528: 'val_score' reached 0.87360 (best 0.87360), saving model to './checkpoints/Transformer=1-epoch=00-train_loss=0.3367-val_score=0.8736.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1320/1320 [02:19<00:00,  9.45it/s, loss=0.513, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 1056: 'val_score' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  50%|█████     | 660/1320 [01:06<01:06,  9.98it/s, loss=0.553, v_num=jwns] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 1584: 'val_score' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1320/1320 [02:12<00:00,  9.99it/s, loss=0.557, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 2112: 'val_score' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1320/1320 [02:12<00:00,  9.99it/s, loss=0.557, v_num=jwns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Seo\\anaconda3\\envs\\Bird\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "c:\\Users\\Seo\\anaconda3\\envs\\Bird\\lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:352: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\Seo\\anaconda3\\envs\\Bird\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:616: UserWarning: Checkpoint directory ./checkpoints/ exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type        | Params\n",
      "--------------------------------------\n",
      "0 | model | CustomModel | 306 M \n",
      "--------------------------------------\n",
      "262 K     Trainable params\n",
      "306 M     Non-trainable params\n",
      "306 M     Total params\n",
      "1,227.192 Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 22.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Seo\\anaconda3\\envs\\Bird\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Seo\\anaconda3\\envs\\Bird\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|█████     | 660/1320 [01:06<01:06,  9.97it/s, loss=0.555, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 528: 'val_score' reached 0.89342 (best 0.89342), saving model to './checkpoints/Transformer=2-epoch=00-train_loss=0.4912-val_score=0.8934.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1320/1320 [02:19<00:00,  9.44it/s, loss=0.537, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 1056: 'val_score' reached 0.89359 (best 0.89359), saving model to './checkpoints/Transformer=2-epoch=00-train_loss=0.7243-val_score=0.8936.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  50%|█████     | 660/1320 [01:06<01:06,  9.88it/s, loss=0.555, v_num=jwns] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 1584: 'val_score' reached 0.89441 (best 0.89441), saving model to './checkpoints/Transformer=2-epoch=01-train_loss=0.5249-val_score=0.8944.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1320/1320 [02:20<00:00,  9.40it/s, loss=0.517, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 2112: 'val_score' reached 0.89482 (best 0.89482), saving model to './checkpoints/Transformer=2-epoch=01-train_loss=0.8859-val_score=0.8948.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  50%|█████     | 660/1320 [01:06<01:06,  9.90it/s, loss=0.538, v_num=jwns] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 2640: 'val_score' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1320/1320 [02:13<00:00,  9.90it/s, loss=0.479, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 3168: 'val_score' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  50%|█████     | 660/1320 [01:06<01:06,  9.99it/s, loss=0.536, v_num=jwns] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 3696: 'val_score' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  50%|█████     | 660/1320 [01:06<01:06,  9.99it/s, loss=0.536, v_num=jwns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Seo\\anaconda3\\envs\\Bird\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "c:\\Users\\Seo\\anaconda3\\envs\\Bird\\lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:352: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\Seo\\anaconda3\\envs\\Bird\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:616: UserWarning: Checkpoint directory ./checkpoints/ exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type        | Params\n",
      "--------------------------------------\n",
      "0 | model | CustomModel | 306 M \n",
      "--------------------------------------\n",
      "262 K     Trainable params\n",
      "306 M     Non-trainable params\n",
      "306 M     Total params\n",
      "1,227.192 Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 22.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Seo\\anaconda3\\envs\\Bird\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Seo\\anaconda3\\envs\\Bird\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|█████     | 660/1320 [01:06<01:06,  9.97it/s, loss=0.484, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 528: 'val_score' reached 0.89505 (best 0.89505), saving model to './checkpoints/Transformer=3-epoch=00-train_loss=0.3972-val_score=0.8951.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1320/1320 [02:19<00:00,  9.44it/s, loss=0.542, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 1056: 'val_score' reached 0.89550 (best 0.89550), saving model to './checkpoints/Transformer=3-epoch=00-train_loss=0.4742-val_score=0.8955.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  50%|█████     | 660/1320 [01:06<01:06,  9.90it/s, loss=0.449, v_num=jwns] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 1584: 'val_score' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1320/1320 [02:12<00:00,  9.94it/s, loss=0.485, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 2112: 'val_score' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  50%|█████     | 660/1320 [01:06<01:06,  9.98it/s, loss=0.421, v_num=jwns] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 2640: 'val_score' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  50%|█████     | 660/1320 [01:06<01:06,  9.98it/s, loss=0.421, v_num=jwns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Seo\\anaconda3\\envs\\Bird\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "c:\\Users\\Seo\\anaconda3\\envs\\Bird\\lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:352: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\Seo\\anaconda3\\envs\\Bird\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:616: UserWarning: Checkpoint directory ./checkpoints/ exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type        | Params\n",
      "--------------------------------------\n",
      "0 | model | CustomModel | 306 M \n",
      "--------------------------------------\n",
      "262 K     Trainable params\n",
      "306 M     Non-trainable params\n",
      "306 M     Total params\n",
      "1,227.192 Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 23.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Seo\\anaconda3\\envs\\Bird\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Seo\\anaconda3\\envs\\Bird\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|█████     | 660/1320 [01:06<01:06,  9.96it/s, loss=0.505, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 528: 'val_score' reached 0.90259 (best 0.90259), saving model to './checkpoints/Transformer=4-epoch=00-train_loss=0.5481-val_score=0.9026.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1320/1320 [02:19<00:00,  9.43it/s, loss=0.464, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 1056: 'val_score' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  50%|█████     | 660/1320 [01:06<01:06,  9.97it/s, loss=0.511, v_num=jwns] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 1584: 'val_score' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  96%|█████████▌| 1269/1320 [02:12<00:05,  9.59it/s, loss=0.462, v_num=jwns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Seo\\anaconda3\\envs\\Bird\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:653: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "for fold_idx, (train_index, val_index) in enumerate(skf.split(train_df, train_df['class'])):\n",
    "    train_fold_df = train_df.loc[train_index,:]\n",
    "    val_fold_df = train_df.loc[val_index,:]\n",
    "\n",
    "    train_dataset = CustomDataset(train_fold_df, 'img_path', mode='train')\n",
    "    val_dataset = CustomDataset(val_fold_df, 'img_path', mode='val')\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, collate_fn=train_collate_fn, batch_size=BATCH_SIZE)\n",
    "    val_dataloader = DataLoader(val_dataset, collate_fn=val_collate_fn, batch_size=BATCH_SIZE*2)\n",
    "\n",
    "    #model = Swinv2Model.from_pretrained(\"microsoft/swinv2-large-patch4-window12to16-192to256-22kto1k-ft\")\n",
    "    model = vit_model\n",
    "    lit_model = LitCustomModel(model)\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='val_score',\n",
    "        mode='max',\n",
    "        dirpath='./checkpoints/',\n",
    "        #filename=f'swinv2-large-resize-fold_idx={fold_idx}'+'-{epoch:02d}-{train_loss:.4f}-{val_score:.4f}',\n",
    "        filename=f'Transformer={fold_idx}'+'-{epoch:02d}-{train_loss:.4f}-{val_score:.4f}',\n",
    "        save_top_k=1,\n",
    "        save_weights_only=True,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    # wandb logger 초기화\n",
    "    wandb_logger = WandbLogger(name=f\"EfficientNetV2Model_Fold{fold_idx}\", project=\"Bird_Competition\", log_model=\"all\")\n",
    "\n",
    "    earlystopping_callback = EarlyStopping(monitor=\"val_score\", mode=\"max\", patience=3)\n",
    "    trainer = L.Trainer(max_epochs=100, accelerator='auto', precision=32, callbacks=[checkpoint_callback, earlystopping_callback], val_check_interval=0.5, logger=wandb_logger)\n",
    "    trainer.fit(lit_model, train_dataloader, val_dataloader)\n",
    "\n",
    "    model.cpu()\n",
    "    lit_model.cpu()\n",
    "    del model, lit_model, checkpoint_callback, earlystopping_callback, trainer\n",
    "    #wandb_logger.experiment.finish()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./open/test.csv')\n",
    "test_df['img_path'] = test_df['img_path'].apply(lambda x: os.path.join('./open', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not len(test_df) == len(os.listdir('./open/test')):\n",
    "    raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(256,256), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
    "])\n",
    "\n",
    "test_collate_fn = CustomCollateFn(test_transform, 'inference')\n",
    "test_dataset = CustomDataset(test_df, 'img_path', mode='inference')\n",
    "test_dataloader = DataLoader(test_dataset, collate_fn=test_collate_fn, batch_size=BATCH_SIZE*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_preds = []\n",
    "for checkpoint_path in glob('./checkpoints/swinv2-large-resize*.ckpt'):\n",
    "    model = Swinv2Model.from_pretrained(\"microsoft/swinv2-large-patch4-window12to16-192to256-22kto1k-ft\")\n",
    "    lit_model = LitCustomModel.load_from_checkpoint(checkpoint_path, model=model)\n",
    "    trainer = L.Trainer( accelerator='auto', precision=32)\n",
    "    preds = trainer.predict(lit_model, test_dataloader)\n",
    "    preds = torch.cat(preds,dim=0).detach().cpu().numpy().argmax(1)\n",
    "    fold_preds.append(preds)\n",
    "pred_ensemble = list(map(lambda x: np.bincount(x).argmax(),np.stack(fold_preds,axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./open/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['label'] = le.inverse_transform(pred_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./submissions/swinv2_large_resize.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bird",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
